data augmentation: No
optimizer: optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=args.weight_decay)
lr_scheduler: optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs, steps_per_epoch=len(train_loader),
                                              cycle_momentum=True,
                                              base_momentum=0.85, max_momentum=0.95, last_epoch=-1,
                                              div_factor=25, final_div_factor=100)
initial_lr: 0.000357